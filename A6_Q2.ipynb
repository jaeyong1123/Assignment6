{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Question 2\n",
    "\n",
    "In this question, you'll go over some of the core terms and concepts in statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part A\n",
    "\n",
    "Write a function, `variance`, which computes the variance of a list of numbers.\n",
    "\n",
    "The function takes one argument: a list or 1D NumPy array of numbers. It returns one floating-point number: the variance of all the numbers.\n",
    "\n",
    "Recall the formula for variance:\n",
    "\n",
    "$$\n",
    "variance = \\frac{1}{N - 1} \\sum_{i = 1}^{N} (x_i - \\mu_x)^2\n",
    "$$\n",
    "\n",
    "where $N$ is the number of numbers in your list, $x_i$ is the number at index $i$ in the list, and $\\mu_x$ is the average value of all the $x$ values.\n",
    "\n",
    "You can use `numpy.array` and your `numpy.mean` functions, but no other NumPy functions or built-in Python functions other than `range()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def variance(nums):\n",
    "    n=nums.shape[0]\n",
    "    s = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        #s = s + nums[i]\n",
    "        #mean = s /n\n",
    "        \n",
    "        mean = np.mean(nums)\n",
    "        s =s + (nums[i] - mean)**2\n",
    "        var = s / (n-1)\n",
    "    return var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2a_test1",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(5987968)\n",
    "x = np.random.random(8491)\n",
    "v = x.var(ddof = 1)\n",
    "np.testing.assert_allclose(v, variance(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2a_test2",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(4159)\n",
    "y = np.random.random(25)\n",
    "w = y.var(ddof = 1)\n",
    "np.testing.assert_allclose(w, variance(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2b_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part B\n",
    "\n",
    "The lecture on statistics mentions latent variables, specifically how you *cannot* know what the underlying process is that's generating your data; all you have is the data, on which you have to impose certain assumptions in order to derive hypotheses about what generated the data in the first place.\n",
    "\n",
    "To illustrate this, the code provided below generates sample data from distributions with mean and variance that are *typically* not known to you. Put another way, **pretend you cannot see the mean (`loc`) and variance (`scale`) in the code that generates these samples; all you usually can see are the data samples themselves.**\n",
    "\n",
    "You'll use the `numpy.mean` and `variance` function you wrote in Part A to compute the statistics on the sample data itself and observe how these statistics change.\n",
    "\n",
    "In the space provided, compute and print the mean and variance of each of the three samples:\n",
    " - `sample1`\n",
    " - `sample2`\n",
    " - `sample3`\n",
    "\n",
    "You can just `print()` them out in the space provided. **Don't modify anything above where it says \"DON'T MODIFY\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2b",
     "locked": false,
     "points": 20,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of sample 1:  9.225549723298691\n",
      "variancec of sample 1:  40.227985133290126\n",
      "mean of sample 2:  9.799833697772822\n",
      "variancec of sample 2:  25.268584205085652\n",
      "mean of sample 3:  10.000880335689784\n",
      "variancec of sample 3:  25.009857369536434\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(5735636)\n",
    "\n",
    "sample1 = np.random.normal(loc = 10, scale = 5, size = 10)\n",
    "sample2 = np.random.normal(loc = 10, scale = 5, size = 1000)\n",
    "sample3 = np.random.normal(loc = 10, scale = 5, size = 1000000)\n",
    "\n",
    "#########################\n",
    "# DON'T MODIFY ANYTHING #\n",
    "#   ABOVE THIS BLOCK    #\n",
    "#########################\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "m1= np.mean(sample1)\n",
    "v1 =variance(sample1)\n",
    "print(\"mean of sample 1: \", m1)\n",
    "print(\"variancec of sample 1: \", v1)\n",
    "\n",
    "m2= np.mean(sample2)\n",
    "v2 =variance(sample2)\n",
    "print(\"mean of sample 2: \", m2)\n",
    "print(\"variancec of sample 2: \", v2)\n",
    "\n",
    "m3= np.mean(sample3)\n",
    "v3 =variance(sample3)\n",
    "print(\"mean of sample 3: \", m3)\n",
    "print(\"variancec of sample 3: \", v3)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2c_prompt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part C\n",
    "\n",
    "Since you don't usually know the *true* mean and variance of the process that presumably generated your data, the mean and variance you compute yourself are *estimates* of the true mean and variance. Explain what you saw in the estimates you computed above as they related to the number of samples. What implications does this have for computing statistics as part of real-world analyses?\n",
    "\n",
    "(Your answer should fit in a Tweet--i.e., keep it under 280 characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2c",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "When the size of sample is 10 (sample1), the mean is 9.22 which is very far from the true mean. When the size is getting bigger and bigger, estimated means are getting close to the true mean (9.80 for sample2 and 10.00 for sample3). Regarding the variance, it is similar with the mean. When the size of sample is 1,000,000, the variance is very close to the true variance. It implies that the more you have the sample size, the better you estimate the true statistics. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
